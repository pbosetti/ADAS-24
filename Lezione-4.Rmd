---
title: "Lezione 4: Bootstrap"
author: "Paolo Bosetti"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    number_sections: true
  html_notebook:
    toc: true
  word_document:
    toc: true
  html_document:
    toc: true
header-includes: \usepackage[italian]{babel}
---

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(modelr)
library(boot)
source("my_lib.R")

knitr::opts_chunk$set(
  fig.dim=c(5,3),      # dimensioni delle figure in pollici
  out.width = "10cm",  # larghezza figure sul documento
  fig.align = "center"
) 
```

# Bootstrap non-parametrico

Calcoliamo l'intervallo di confidenza per la media campionaria di un singolo campione (equivalente di un T-test a un campione a due lati).

Creiamo una tabella di dati e utilizziamo la funzione `boot()` per calcolare i **campioni di bootstrap**, cioè le $R$ repliche del calcolo della statistica di interesse (media) su altrettanti campioni ottenuti dal campione di partenza mediante ricampionamento con reinserimento.

Si noti che l'argomento `statistic` di `boot()` deve essere una funzione con due argomenti: al primo viene passato il vettore dei dati originali; al secondo argomento viene passato, di volta in volta e per `R` volte, il vettore degli indici corrispondenti a ciascun campione di bootstrap (e sono tutti vettori lunghi tanto quanto il vettore dei dati originali):

```{r}
set.seed(1)
R <- 50000
data <- runif(100, 1, 10)

data.b <- boot(
  data,
  statistic = function(x, i) mean(x[i]),
  R = R
)
data.b
```

È come dire che se abbiamo il campione 

```{r}
(v <- rnorm(5))
```

i campioni di bootstrap li generiamo a partire da una lista di sequenze casuali di indici:

```{r}
index <- list(
  sample(1:5, 5, replace=T),
  sample(1:5, 5, replace=T),
  sample(1:5, 5, replace=T),
  sample(1:5, 5, replace=T)
)
index
```

a cui corrispondono i campioni di bootstrap:

```{r}
list(
  v[index[[1]]],
  v[index[[2]]],
  v[index[[3]]],
  v[index[[4]]] 
)
```
e le corrispettive stime:

```{r}
list(
  mean(v[index[[1]]]),
  mean(v[index[[2]]]),
  mean(v[index[[3]]]),
  mean(v[index[[4]]])
)
```

Quanto sopra per $R=4$. Se vogliamo realizzare migliaia di campioni di bootstrap o automatizziamo questa procedura (ad es. usando le funzioni `map`, e questo può essere un valido esercizio), oppure usiamo la funzione `boot`, che chiama appunto la funzione passata all'argomento `statistic` applicandola al vettore dei dati (nell'esempio: `v`) e passando di volta in volta un nuovo vettore di indici (nell'esempio: `index[i]`).

Ora `data.b` contiene le informazioni di bootstrap. In particolare, è possibile usare la funzione `boot.ci` per calcolare i limiti dell'intervallo di confidenza (qui confrontato con quello calcolato con il `t.test`):

```{r}
(data.ci <- boot.ci(data.b, conf=0.95, type="perc"))
(data.tt <- t.test(data))
```

Si noti che l'oggetto restituito da `boot.ci` contiene il campo `$percent`, che è un vettore di 5 elementi. Secondo quanto dichiarato dall'help in linea, gli ultimi due elementi sono gli estremi dell'intervallo. Confrontiamoli graficamente con quelli calcolati secondo Student:

```{r}
data.orig <- tibble(
  i = seq_along(data) * 500,
  y = data
)

tibble(
  i = 1:R,
  t = data.b$t
) %>% 
  ggplot(aes(x=i, y=t)) + 
  geom_point(size=0.5) +
  geom_point(data=data.orig, aes(x=i, y=y), color=gray(0.5)) +
  geom_hline(yintercept=data.tt$conf.int[1], color="red") +
  geom_hline(yintercept=data.tt$conf.int[2], color="red") +
  geom_hline(yintercept=data.ci$percent[4], color="green", linetype=2) +
  geom_hline(yintercept=data.ci$percent[5], color="green", linetype=2)
```

**Esercizio**: trasformare l'ultimo grafico in un istogramma con le linee verticali che rappresentano l'intervallo di confidenza.

```{r}
tibble(
  i = 1:R,
  t = data.b$t
) %>% 
  ggplot(aes(x=t)) +
  geom_histogram(bins=50, fill=grey(0.5), color="black") +
  geom_vline(xintercept=data.ci$percent[4:5], color="red") +
  geom_vline(xintercept=data.tt$conf.int, color="blue")

```
# Regressione lineare

Consideriamo il caso di una regressione lineare di un modello di primo grado come il seguente:

$$
y = a + bx
$$

Vogliamo stimare l'intervallo di confidenza sui due parametri $a$ e $b$.

Facciamo un esempio, generandoci un set di `r (N <- 10)` punti:

```{r}
set.seed(1)
k <- c(a=10, b=2)

data <- tibble(
  x = runif(N, 0, 10),
  y = k["a"] + k["b"] * x + rnorm(N, sd=2)
)

data %>% 
  ggplot(aes(x=x, y=y)) + 
  geom_point() +
  geom_smooth(method="lm", formula=y~x)

lm(y~x, data=data)$coefficients
```

Per calcolarci l'intervallo di confidfenza con la tecnica bootstrap abbiamo bisogno di una funzione che mi restituisca i due parametri a partire dalla matrice (o tabella) di dati:


```{r}
linfit <- function(data) {
  N <- length(data$x) 
  A <- matrix(c(rep(1, N), data$x), nrow=N, byrow=F)
  res <- as.vector(MASS::ginv(A) %*% data$y)
  names(res) <- c("a", "b")
  return(res)
}
```

Con questa funzione possiamo costruirci l'oggetto bootstrap:

```{r}
data.b <- boot(data, R=10000, statistic=function(x, i) linfit(x[i,]))
data.b
```

E dall'oggetto bootstrap possiamo clacloarci i due intervalli di confidenza su $a$ (`index=1`) e $b$ (`index=2`):

```{r}
boot.ci(data.b, type="perc", index=1)
boot.ci(data.b, type="perc", index=2)
```


## Intervallo di confidenza per regressione ai minimi quadrati

Per calcolare i limiti dell'intervallo di confidenza alla sezione precedente ci sarebbero anche metodi analitici. Tuttavia, se la funzione da regredire non è analitica e la regressione viene effettuata con il metodo dei minimi quadrati questi metodi non sono applicabili, mentre il bootstrap lo è.

Consideriamo il modello di contatto visto nella sezione finale della regressione, che qui richiamiamo identico:

```{r}
f <- function(t, t0=0, bias=0, a=1) {
  b <- -2 * a * t0
  c <-  bias + a * t0^2
  y <- a * t^2 + b * t + c
  return(ifelse(t < t0, bias, y))
}
```

Costruiamo su tale modello un set di dati:

```{r}
set.seed(1)
onset <- 2.5
bias <- 3
a <- 1

data <- tibble(
  t = seq(-10, 10, length.out=100),
  yn = f(t, onset, bias, a),
  y = yn + rnorm(length(t), 0, 2)
)

data %>% 
  ggplot(aes(x=t, y=y)) + 
  geom_point() +
  geom_line(aes(y=yn), color="red")
```

La regressione ai minimi quadrati è:

```{r}
fit <- nls(y~f(t, t0, b, a), data=data, start=list(t0=0, b=0, a=1))
summary(fit)
```

Possiamo estrarre i parametri della regressione in questo modo:

```{r}
fit$m$getPars()
```

Come sopra, per applicare il bootstrap dobbiamo definire una funzione che ci restutuisca i parametri a partire dai dati:

```{r}
stats <-function(data) {
  fit <- nls(y~f(t, t0, b, a), data=data, start=list(t0=0, b=0, a=1))
  fit$m$getPars()
}

stats(data)
```

Ora possiamo effettuare il bootstrap e calcolare gli intervalli di confidenza:

```{r}
data.b <- boot(data, R=10000, statistic=function(x, i) stats(x[i,]))
boot.ci(data.b, type="perc", index=1)
boot.ci(data.b, type="perc", index=2)
boot.ci(data.b, type="perc", index=3)
```

Per visualizzarli, cominciamo inserendo i valodi in una lista:

```{r}
ci <- list(
  t0 = boot.ci(data.b, type="perc", index=1)$percent[4:5],
  bias = boot.ci(data.b, type="perc", index=2)$percent[4:5],
  a = boot.ci(data.b, type="perc", index=3)$percent[4:5]
)
ci
```

Possiamo visualizzare gli intervalli dei parametri `t0` e `bias` (i più interessanti per il caso in esame) come rettangoli:

```{r}
data %>% 
  ggplot(aes(x=t, y=y)) + 
  geom_rect(xmin=ci$t0[1], xmax=ci$t0[2], ymin=-Inf, ymax=Inf, fill=gray(0.5))  +
  geom_rect(ymin=ci$bias[1], ymax=ci$bias[2], xmin=-Inf, xmax=Inf, fill=gray(0.5))  +
  geom_point() +
  coord_cartesian(xlim=c(0,5), ylim=c(0, 10))
```

Per visualizzare la *banda di confidenza* dobbiamo costruirci una funzione che, per ogni valore del predittore `t`, calcoli il modello per tutte le possibili combinazioni estreme dei parametri nei rispettivi intervalli di confidenza, resitutuendo il massimo (bordo superiore) o il minimo (bordo inferiore):

```{r}
f_conf <- function(t, f, ci, upper=T) {
  df <- expand.grid(ci)
  df$f <- f(t, df$t0, df$bias, df$a)
  return(ifelse(upper, max(df$f), min(df$f)))
}
```

Con questa funzione possiamo ora ottenere la banda di confidenza:

```{r}
data %>% 
  mutate(
    upper = map_dbl(t, ~ f_conf(., f, ci)),
    lower = map_dbl(t, ~ f_conf(., f, ci, upper=F))
  ) %>% 
  ggplot(aes(x=t)) +
  geom_point(aes(y=y)) + 
  geom_line(aes(y=yn)) + 
  geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.5)
```

