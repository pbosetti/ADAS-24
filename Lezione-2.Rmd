---
title: "Tidyverse"
author: "Paolo Bosetti"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    number_sections: true
  html_document:
    toc: true
  word_document:
    toc: true
  html_notebook:
    top: true
header-includes: \usepackage[italian]{babel}
---

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
# ATTENZIONE: questo è un blocco di setup: viene eseguito automaticamente PRIMA 
# di eseguire qualunque blocco successivo. Fate la prova: riavviate RStudio, 
# Aprite questo file e eseguite ad esempio il secondo blocco R. Vedrete che 
# questo blocco viene eseguito per primo.

# ATTENZIONE: se cliccate sul menu ingranaggio DOPO aver chiamato questo blocco
# "setup", modificate le "Default chunk options", cioè le opzioni per tutti i 
# blocchi successivi. Quindi se disabilitate la visualizzazione del codice, 
# la disabilitate per tutti i blocchi successivi. Ve ne accorgete perché compare
# qualcosa di simile:
#  knitr::opts_chunk$set(eval = FALSE, include = FALSE)
# Se invece volete personalizzare SOLO QUESTO blocco, inserite a mano le opzioni 
# del blocco, come sopra, oppure rimuovete il nome "setup", cliccate 
# sull'ingranaggio, modificate le impostazioni e aggiungete il nome setup.

# Eseguo lo script con le mie funzioni personalizzate:
source("my_lib.R")
```



# Tidyverse

`Tidyverse` è una meta-libreria, cioè una collezione di librerie, che trasforma il modo in cui si utilizza R per descrivere algoritmi di manipolazione e analisi dati.

```{r}
library(tidyverse)
```

Caricando la libreria si vede che in effetti si tratta di 9 librerie separate:

1. `tibble`: data frame evoluti
1. `readr`: lettura/scritura file
1. `dplyr`: manipolazione dati
1. `tidyr`: riorganizzazione di data frame 
1. `ggplot2`: realizzazione grafici
1. `purrr`: programmazione funzionale (mappe)
1. `stringr`: manipolazione stringhe
1. `forcats`: manipolazione fattori
1. `lubridate`: manipolazione date e intervalli di tempo

Noi vedremo in particolare le prime 6. Ciascuna di queste librerie, se necessario, può essere caricata separatamente, oppure possiamo caricarle tutte come `tidyverse`.

Si noti che il messaggio di conflitto ottenuto al caricamento è atteso e del tutto normale.

## Pipe

Oltre alle 9 librerie sopra elencate, `tidyverse` fornisce l'**operatore *pipe***. Una *pipe* è un *condotto* che passa l'output di una funzione all'input di una seconda funzione. Lo scopo è di rendere il codice più leggibile, evitando funzioni nidificate, e efficiente, evitando eccessive variabili intermedie. Utilizzando una *pipe* si riscrive una generica espressione `f(x, y, ...)` come `x %>% f(y, ...)`. Generalmente la *pipe* è indicata con `%>%`, ma esiste anche la forma alternativa `|>`.

In R standard:

```{r}
round(mean(rnorm(10)), 2)
```

Questa espressione è particolarmente scomoda da leggere (la prima operazione è quella più interna) e prona ad errori (troppe parentesi). Questa sequenza di operazioni può essere resa più chiara ricorrendo a variabili intermedie:

```{r}
v <- rnorm(10, 2)
v.m <- mean(v)
round(v.m, 2)
```

Ma le variabili intermedie sono meno efficienti e possono essere scomode o prone ad errori (riuso di variabili con lo stesso nome).

Con l'operatore *pipe* si evitano questi problemi: le operazioni vengono chiaramente elencate una dopo l'altra in ordine logico, e l'output di ogni funzione diventa **il primo argomento** della funzione successiva:

```{r}
rnorm(10, 2) %>%  
  mean %>% 
  round(2)
```


## Tibble

Le tibble sono versioni evolute dei data frame, compatibili con questi ultimi. Hanno alcuni vantaggi:

1. sono più facili da creare
2. sono più robuste
3. sono più facili da visualizzare

Nella creazione di un data frame non è possibile fare riferimento ad un'altra colonna, ma bisogna appoggiarsi a variabili intermedie:

```{r}
v <- c(1,7,3,10,3,2,2) # variabile intermedia
data.frame(
  A = v,
  B = v^2
)

# Oppure aggiungere una colonna in un secondo momento:
df <- data.frame(A=c(1,7,3,10,3,2,2))
df$B <- df$A^2
```

Creando una tibble, a differenza che nei data frame, è possibile invece che una colonna faccia direttamente riferimento ad una colonna precedente:

```{r}
tbl <- tibble(
  A = 1:10,
  B = A^2
)
```

Mentre un data frame viene sempre stampato per intero (che per data frame molto lunghi può essere un problema), una tibble viene sempre limitata alle prime 10 righe. Se si vogliono più (o meno) righe, bisogna stamparla con la funzione `print` passando l'opzione `n`:

```{r}
tibble(
  A=1:100,
  B=NA
) %>% print(n=20)
```

Si osservi che le colonne passate a `tibble` devono avere tutte la stessa lunghezza oppure lunghezza pari a 1. In quest'ultimo caso il singolo valore viene ripetuto (come per `NA` nell'esempio). Nel caso di `data.frame`, invece, è possibile passare vettori più corti, con lunghezza pari a un sottomultiplo della lunghezza delle colonne più lunghe: in questo caso il vettore più corto viene *riciclato*:

```{r}
data.frame(
  A=1:6,
  B=c("uno", "due")
)
```

Questo automatismo però è pericoloso (perché l'utente non se ne accorge), ed è quindi stato rimosso da `tibble`.

È sempre possibile convertire una tibble in data frame e viceversa:

```{r}
tbl %>% 
  as.data.frame() %>% 
  tail()
df %>% tibble() %>% str()
```

È possibile creare tibble passando i dati per riga invece che per colonna, mediante la funzione `tribble` (*TRansposed tIBBLE*). La prima riga deve contenere i nomi delle colonne preceduti da `~`:

```{r}
tribble(
  ~x, ~y, ~z,
  "a", 1, 10,
  "b", 5, 8,
  "c", 3, 12
)
```

## Input/Output da file

Esistono le versioni *tidy* delle funzioni per leggere e scrivere file di testo:

* `read_csv()`
* `read_csv2()`
* `read_table()`
* `read_fwf()`

* `write_csv()`
* `write_csv2()`
* `write_table()`
* `write_fwf()`

Il principale vantaggio di queste funzioni rispetto alle equivalenti con il punto nel nome (es. `read.table`) è che esse restituiscono direttamente una tibble.

Vedere il cheatsheet qui: <https://rstudio.github.io/cheatsheets/data-import.pdf>.

Il sito <https://paolobosetti.quarto.pub>, nella sezione *Example data*, fornisce alcuni file con dati di esempio che useremo durante il corso. Per semplificarne il download, creiamo il file `my_lib.R` contenente la funzione indicata sul sito e lo carichiamo all'inizio di ogni notebook con il comando `source("my_lib.R")`. A questo punto possiamo caricare un file come tibble in questo modo:

```{r}
read_table(example_url("cotton.dat"))
```
A quanto pare, l'importazione non è andata a buon fine. Scarichiamo il file grezzo per capire come mai:

```{r}
read_file(example_url("cotton.dat")) %>%
  str_trunc(200) %>% # Tronco ai primi 200 caratteri
  cat()              # Stampo la stringa risultante
```

Le prime 4 righe in effetti sono commenti che iniziano col carattere `#`, quindi è opportuno specificare il carattere di commento in `read_table`:

```{r}
data <- read_table(example_url("cotton.dat"), comment = "#")
data
```



## Gestione delle tabella dati: dplyr

La libreria `dplyr` (parte di Tidyverse) fornisce funzioni utili alla manipolazione di tibbe.

Tidiverse contiene alcune tibble di esempio, utili per impararne l'uso. Tra queste la tibble `starwars`:

```{r}
starwars
```

### Filtrare le righe

"Filtrare" significa selezionare solo le righe che rispondono ad alcuni criteri. Ad esempio, solo i personaggi più alti di 180 cm e con capelli castani:

```{r}
starwars %>% 
  filter(height > 180, eye_color=="brown")
```

### Riordinare le righe

Altra operazione comune è riordinare una tabella secondo uno o più criteri:

```{r}
starwars %>% 
  filter(height > 180, eye_color=="brown") %>% 
  arrange(desc(height), mass)
```

I criteri (che devono essere espressioni logiche, quindi non confindere "=" con "==") vengono passati separati da virgole e vengono applicati in sequenza. In questo esempio, cioè i personaggi vengono *prima* ordinati per statura e poi, a pari statura, per massa.


### Selezione di colonne

Per selezionare solo alcune colonne si usa `select`:

```{r}
starwars %>% 
  filter(height > 180, eye_color=="brown") %>% 
  arrange(desc(height), mass) %>% 
  select(pianeta_natale=homeworld, name:hair_color & !height) %>% 
  slice_head(n=5)
```

Gli argomenti di `select` sono:

* nomi di colonne
* intervalli di colonne (`name:hair_color`)
* espressioni logiche (`name:hair_color & !height`)
* coppie `nuovo_nome = nome_precedente`


### Modificare una colonna

©on `mutate` è possibile modificare una colonna esistente o creare una nuova colonna sulla base di una o più colonne esistenti, mediante espressioni (vettorializzate!):

```{r}
starwars %>% 
  mutate(
    height = height / 100,
    BMI = (mass/height^2) %>% round(1)
  ) %>% 
  relocate(BMI, .after=height) %>% 
  arrange(desc(BMI))
```

Si noti `relocate`, che consente di spostare una colonna prima o dopo un'altra colonna.


### Raggruppamento e sommario

Se vogliamo raggruppare tutte le osservazioni (righe) avente una colonna in comune e applicare una funzione di aggregazione, utilizziamo `group_by` e `summarise`. La prima funzione si limita a preparare la tabella individuando i gruppi, ma non modifica nulla:

```{r}
starwars %>% 
  group_by(species, sex)
```

La seconda funzione crea di fatto i sommari, in questo caso come media dei valori:

```{r}
starwars %>% 
  group_by(species, sex) %>%
  summarise(
    height = mean(height, na.rm=TRUE),
    mass = mean(mass, na.rm=T)
  ) %>% 
  arrange(desc(height))
```

Per inciso, si noti che la funzione `mean` specifica `na.rm=T`, cioè di omettere tutti i valori `NA` nel calcolare la media:

```{r}
mean(c(1, NA, 3), na.rm=T)
```


### Riorganizzazione

Nel linguaggio dell'analisi dati si dice che si preferiscono dati organizzati in maniera *tidy*, cioè **un'osservazione per riga, un osservando per colonna**. Per capire il significato di questa affermazione, consideriamo un'altra tabella di esempio, `relig_income`. In questo caso, le colonne riportano il conteggio di soggetti parte di un campione statistico, raggruppati per religione (righe) e per classe di retribuzione (colonne). Questa tabella **non è *tidy***, dato che lo stesso osservando (conteggio) è distribuito su più colonne:

```{r}
relig_income
```

La tabella può essere resa *tidy* mediante `pivot_longer`:

```{r}
income <- relig_income %>% 
  pivot_longer(
    !religion,            # lavora su tutte le colonne tranne religion
    names_to = "income",  # i nomi colonna finiscono nella colonna "income"
    values_to = "count"   # i valori (conteggi) nella colonna "count"
  )
income
```

La trasformazione inversa si ottiene con `pivot_wider`:

```{r}
income %>% 
  pivot_wider(
    names_from = income,
    values_from = count
  )
```

## Programmazione funzionale e mappatura di funzioni

Gran parte delle funzioni R opera direttamente su vettori, elemento per elemento, quindi generalmente non c'è bisogno di loop. Per i casi in cui sia necessario operare la stessa trasformazione su tutti gli elementi di un vettore e la trasformazione in questione non è vettorializzata, è possibile utilizzare le [funzioni di `purrr`](https://rstudio.github.io/cheatsheets/purrr.pdf).

In generale esiste una famiglia di funzioni il cui nome comincia con `map_` seguito da un suffisso che indica il tipo del vettore generato (`_int`, `_dbl`, `_chr`, ecc.). Il primo argomento (eventualmente passato via pipe) è il vettire su cui operare, il secondo è una funzione di un solo argomento:

```{r}
map_dbl(1:3, function(x) {x*2})
```

La funzione può essere abbreviata, sostituendo `function(x)` con `~`, e `x` con `.`:

```{r}
1:3 %>%  map_dbl(~ .*2) %>% str()
```

Come si vede, il suffisso **garantisce** sul tipo di vettore che si ottiene:

```{r}
1:10 %>% map_int(~ . * 2) %>%  str()
```

Esiste anche la funzione `map` (senza sufisso), che restituisce sempre una **lista**:

```{r}
1:10 %>% map(~ .*2) %>% str()
```

Per fare un esempio d'uso, riprendiamo la tabella `income` (versione *tidy* di `relig_income`). Vogliamo esprimere le quote in percentuale anziché in numero assoluto. Per questo ci servono i totali di individui in ogni categoria.

Calcoliamo la dimensione del campione per ogni religione:

```{r}
income %>% 
  group_by(religion) %>% 
  summarise(total = sum(count))
```

L'uso in sequenza di `group_by` e `summarise` è così comune che le ultime versioni di `dplyr` consentono una semplificazione:

```{r}
totals <- income %>% 
  summarise(total = sum(count), .by=religion)
```

Ora possiamo aggiungere una colonna con la percentuale:

```{r}
income %>% 
  mutate(
    total = map_dbl(religion, ~ totals[totals$religion==.,]$total),
    perc = (count/total*100) %>% round(2)
  )
```

Oppure, in un colpo solo:

```{r}
income %>% 
  mutate(
    perc = map2_dbl(religion, count, ~ (.y/totals[totals$religion == .x,]$total * 100) %>% round(2) )
  )
```

In realtà, l'operazione sopra eseguita consiste di unire due tabelle secondo una colonna comune, che agisce da cerniera. Questa operazione nel linguaggio dei database si chiama *left join*, e la libreria `dplyr` fornisce proprio una funzione equivalente:

```{r}
income %>% 
  left_join(totals, by="religion") %>% # "religion" è la colonna che fa da cerniera per l'unione
  mutate(
    perc = (count/total*100) %>% round(2)
  )
```

Anche in colpo solo, evitando di definire la tabella `totals` e creandola invece al volo:

```{r}
income %>% 
  left_join(summarise(., total=sum(count), .by=religion)) %>% 
  mutate(perc = (count/total*100) %>% round(2))
```
Notare che la pipe passa un oggetto come primo argomento alla funzione successiva, e se si vuole riutilizzare lo stesso argomento in altre posizioni basta usare la variabile speciale `.`, come sopra in `summarise(., ...`.



# Grafici con `ggplot2`

D'ora in avanti non utilizzeremo più le funzioni di plot base di R, ma ricorreremo piuttosto alla libreria `ggplot2` im clusa in `tidyverse`. È una libreria studiata per realizzare grafici di alta qualità evitando soluzioni che sono considerate fuorvianti o poco chiare.

La libreria è basata sulla funzione `ggplot`, che accetta come primo argomento un data frame o una tibble.

Il secondo argomento è chiamato *mapping* e rappresenta l'*estetica*, cioè definisce il ruolo delle varie colonne della tibble (ascissa, ordinata, colore, gruppo, ecc.). Il mapping si crea con la funzione `aes` (che sta per *aesthetics*):

```{r}
tibble(
  v1 = 1:10,
  v2 = v1 ^ 2,
  v3 = v2 + 10
) %>% 
  ggplot(aes(x=v1, y=v2)) 
```

Come si nota, `ggplot` da sola non crea nessun grafico, ma le etichette degli assi sono giuste e l'estensione degli assi stessi è sufficiente a contenere tutti i dati nella tibble.

Per aggiungere serie grafiche si usano comandi di *geometria*, che iniziano con il suffisso `geom_`:

```{r}
tibble(
  v1 = 1:10,
  v2 = v1 ^ 2,
  v3 = v2 + 10
) %>% 
  ggplot(aes(x=v1, y=v2)) +
  geom_line() +
  geom_point(color="red", size=4)
```

Per aggiungere una seconda serie è necessario specificare una differente estetica in una differente geometria. La logica è:

* le estetiche comuni alle varie serie (ad esempio l'ascissa) si mettono in `ggplot`
* le estetiche proprie di ciascuna serie (le ordinate) si mettono nelle geometrie

```{r}
df <- tibble(
  t = 1:10,
  v1 = t ^ 2,
  v2 = v1 + 10
) 

df %>% 
  ggplot(aes(x=t)) +
  geom_line(aes(y=v1), color="red") +
  geom_line(aes(y=v2), color="green") +
  labs(x="Tempo", y="Tensione", title="Esempio")
```

In realtà, se i dati sono in formato *tidy* le serie possono essere definite mediante l'estetica stessa, ottenendo automaticamente anche la legenda:

```{r}
df %>% 
  pivot_longer(v1:v2) %>% # rendo la tibble tidy
  ggplot(aes(x=t, y=value)) +
  geom_line(aes(color=name)) +
  geom_point(color="blue") +
  labs(
    x="Tempo (s)",
    y="Tensione (V)",
    title="Misure di tensione",
    color="Sensore"
  )
```

Da notare:

* estetiche come `color` (e `linewidth`, `linestyle`, `fill`, `shape`, ecc.) possono essere specificate 
  - nella funzione `aes`, e fungono da aggregatori di serie
  - come argomenti di `geom_`, e si applicano a tutti gli oggetti di quella geometria
* la funzione `labs` consente di specificare le etichette per assi, grafico *e legenda*

Vogliamo ora realizzare qualche grafico per illustrare i dati di reddito nella tabella `income`. Anzitutto trasformiamo la colonna `income` da stringa in colonna numerica, che si servirà più avanti per poter riordinare i dati: Ci creiamo una tibble di supporto che definisce le corrispondenze numeriche per ogni intervallo di reddito:

```{r}
(values <- tibble(
  income = relig_income %>% select(!religion) %>% names(),
  v = c((1:5)*10, 75, 100, 150, 300, 0)
))
```

Con un *left join* importiamo questi valori nella tabella originale:

```{r}
income2 <- income %>% 
  left_join(values) %>% 
  rename(income_n=v) %>% 
  relocate(income_n, .after=income) %>% 
  left_join(summarise(., total=sum(count), .by=religion)) %>% 
  mutate(
    income = factor(income, ordered=T, levels=values$income),
    perc = (count/total*100) %>% round(2)
  )

income2
```
Si noti che la colonna `income` è stata ridefinita come `factor(income, ordered=T, levels=values$income)`: in questo modo gli intervalli di reddito vengono rappresentati come fattori (cioè variabili categoriche) ordinati (`ordered=T`) secondo la sequenza logica (come in `values$income`).

Possiamo ora realizzare un grafico a barre sovrapposte, filtrando solo le righe per cui `income_n != 0`:

```{r}
income2 %>% 
  filter(income_n != 0) %>%
  ggplot(aes(x=religion, y=perc, fill=income)) +
  geom_col() +
  coord_flip() +
  scale_fill_viridis_d()
```

Il grafico, infine, può essere migliorato ordinando le religioni in funzione di quelle che hanno la categoria dei più ricchi più numerosa. Per ottenere questo risultato cambiamo la sequenza di ordinazione del fattore `religion`:

```{r}
religion_ord <- income2 %>% 
  filter(income_n == 300) %>% # considero solo i più ricchi
  arrange(desc(perc)) %>%     # in ordine decrescente
  pull(religion) %>%          # estraggo solo la colonna religion
  factor(ordered = T)         # trasformo in vettore ordinato

religion_ord
```
Ora trasformo `income2` modificando l'ordine intrinseco del fattore `religion` e rifaccio il grafico:

```{r}
income2 %>% 
  mutate(
    religion = factor(religion, levels=religion_ord, ordered=T)
  ) %>% 
  filter(income_n != 0) %>% 
  ggplot(aes(x=religion, y=perc, fill=income)) +
  geom_col() +
  geom_hline(yintercept=100, linetype=2) +
  coord_flip() +
  scale_fill_viridis_d() +
  labs(
    x="Religione",
    y="Sul totale (%)",
    fill="Reddito"
  )
```

Esercizio: usando un *left join* tradurre i nomi delle religioni nel grafico.


# Statistica inferenziale

## Test di Student

Caso più generale: test a due campioni, a due lati: creiamo due campioni `s1`e `s2` a partire dalla distribuzione normale. I due campioni avranno dimensioni differenti e saranno estratti da popolazioni con valori attesi e varianze *leggermente* differenti:

```{r}
set.seed(321)

m <- c(10.1, 10.2)
s <- c(0.2, 0.1)
n <- c(10, 14)

s1 <- rnorm(n[1], m[1], s[1])
s2 <- rnorm(n[2], m[2], s[2])

ggplot() +
  geom_point(aes(x=1:n[1], y=s1, color="s1")) +
  geom_point(aes(x=1:n[2], y=s2, color="s2")) +
  geom_hline(aes(color="s1", yintercept=mean(s1))) +
  geom_hline(aes(color="s2", yintercept=mean(s2))) +
  labs(x="ordine", y="valore", color="campione")
```

Per prima cosa è necessario effettuare un test della varianza:

```{r}
(vt <- var.test(s1, s2))
```
Il $p$-value pari a `r vt$p.value %>% round(3)` corrisponde ad una probabilità di errore troppo alta per poter scartare l'ipotesi nulla: di conseguenza, concludiamo che **i due campioni provengono da popolazioni con la medesima varianza**, cioè sono campioni omoschedastici.

A questo punto posso procedere col test di Student, specificando opportunamente l'opzione `var.equal` (con una soglia del 5% sulla probabilità d'errore di tipo I):

```{r}
(tt <- t.test(s1, s2, var.equal = (vt$p.value > 0.05), conf.level=0.99))
```

Concludiamo che, con una probabilità d'errore pari a `r tt$p.value %>% round(3)`, i due campioni **non possono provenire dalla stessa popolazione**, cioè che vale $H_1:~\mu1\neq\mu2$.

Il T-test riporta le seguenti informazioni notevoli:

* la statistica di test $t_0=`r tt$statistic`$
* i gradi di libertà $n_1+n_2-2=`r sum(n)-2`$
* il *p*-value `r tt$p.value`
* i limiti dell'intervallo di confidenza

La coppia di ipotesi effettivamente verificate è:

\begin{align*}
H_0 &: \mu_1-\mu_2 = \mu_0 \\
H_1 &: \mu_1-\mu_2 \neq \mu_0
\end{align*}
dove $\mu_0$ è il parametro `mu=0` usato nella funzione `t.test()`.

Come detto sopra, solo un *p*-value piccolo (solitamente almeno minore di 0.05) ci consente di rigettare $H_0$.

L'intervallo di confidenza **è calcolato relativamente a $\mu_0$**: se nella funzione `t.test` il valore del parametro `mu` (con default a `0`) risulta interno all'intervallo, allora si accetta $H_0$ con il livello di confidenza assegnato (`conf.level`, default a 0.95), e viceversa.

### T-tes a un lato

Si noti che se per gli stessi campioni si valuta il corrispondente test a un lato, osservando che $\bar s_1 < \bar s_2$:

```{r}
t.test(s1, s2, 
       var.equal=(vt$p.value>=0.05), 
       mu=0,
       alternative = "less",
       conf.level=0.95)
```

si ottiene un $p$-value minore, cioè si può scartare l'ipotesi nulla con più forza: quando cioè si può già escludere uno dei due lati, il test a un lato è **più potente** (nel senso che ha una maggior potenza).


## Box plot

Dal punto di vista grafico, la differenza tra i due campioni `s1` e `s1` può essere visualizzata con un *box-plot*.

Per crearlo, riorganizziamo i dati in modo da utilizzare una tibble. La funzione `geom_boxplot()` vuole un'estetica in cui in ordinata ci siano i valori e in ascissa una variabile categorica da utilizzare come chiave di raggruppamento:

```{r}
df <- tibble(
  i = c(1:n[1], 1:n[2]),
  sample = c(rep("s1", n[1]), rep("s2", n[2])),
  values = c(s1, s2)
) 

df %>% 
  ggplot(aes(x=sample, y=values)) +
  geom_boxplot(varwidth=T)

# La tibble rende anche più semplice realizzare il grafico a dispersione:
df %>% 
  ggplot(aes(x=i, y=values, color=sample)) +
  geom_point()
```

Osserviamo che per entrambi i campioni il box-plot suggerisce che i punti massimi siano delle anomalie. Verifichiamo questa possibilità.


## Anomalie

### Criterio di Chauvenet

Il criterio di Chauvenet non è disponibile in R, ma è facile costruire una funzione che lo implementi:

```{r}
require(glue)

chauvenet <- function(x, threshold=0.5) {
  abs.diff <- abs(x - mean(x)) / sd(x) # vettore delle differenze
  s0 <- max(abs.diff)                  # massima diff.
  i0 <- which.max(abs.diff)            # posizione mass. diff.
  freq <- length(x) * pnorm(s0, lower.tail = F)
  result <- list(
    s0 = s0,
    index = i0,
    value = x[i0],
    reject = freq < threshold
  )
  samp <- deparse(substitute(x)) # restituisce l'espressione passata come argomento 'x'
  print(glue("Chauvenet's criterion for sample {samp}"))
  print(glue("Suspect outlier: {i0}, value {x[i0]}"))
  print(glue("Expected frequency: {freq}, threshold: {threshold}"))
  print(glue("Decision: {d}", d=ifelse(result$reject, "reject it", "keep it")))
  invisible(result)                    # Il risultato resitituito e invisibile
}

cs1 <- chauvenet(s1)
cs2 <- chauvenet(s2)
```

Si osserva che secondo questo criterio entrambi i massimi valori di `s1` e `s2` sono anomali. Decidiamo quindi di eliminarli dai rispettivi vettori, sostituendoli con `NA` (lavoriamo su una coppia dei vettori iniziali):


```{r}
s1_2 <- s1
s2_2 <- s2

if (cs1$reject) s1_2[cs1$index] <- NA
if (cs2$reject) s2_2[cs2$index] <- NA

s1_2
s2_2
```

Realizziamo nuovamente il box-plot, dopo aver rimosso tutte le righe con almeno un `NA` con la funzione `na.omit()`:

```{r}
tibble(
  i = 1:(n[1] + n[2]),
  sample = c(rep("s1", n[1]), rep("s2", n[2])),
  values = c(s1_2, s2_2)
) %>% 
  na.omit() %>% 
  ggplot(aes(x=sample, y=values)) +
  geom_boxplot(varwidth=T)
```

### Test di Grubb

Nella realtà, piùttosto che applicare il test di Chauvenet si preferisce ricorrere al test di Grubb (fornito dalla funzione `grubbs.test()` del pacchetto `outliers`):

```{r}
library(outliers)
grubbs.test(s1)
```

la quale conferma che il punto massimo di `s1` è un'anomalia. Dato che però il test di Grubb non fornisce *l'indice* dell'elemento anomalo, è necessario ricavarlo manualmente come indice dell'elemento col massimo scarto rispetto alla media del campione:

```{r}
which.max(abs(s1 - mean(s1)))
```



# Esercizi

## Anomalie

Dopo aver eliminato dai campioni `s1` e `s2` gli eventuali punti anomali mediante test di Grubb, verificare con un test di Student se i valori attesi dei due campioni siano uguali o meno.


## Test di Student a un campione

Considerare i seguenti dati:

```{r message=FALSE}
read_table(example_url("diet.dat"))
```

verificare l'ipotesi che i valori della colonna `cTime` quando `diet` è uguale a `D` provengano da una popolazione con media $\mu_0=59$

## Test di Student accoppiato

Considerare i seguenti dati: essi rappresentano delle misure di durezza effettuate con due diversi strumenti (indentatori `Tip1` e `Tip2`). Si ha il sospetto che uno dei due strumenti non sia correttamente calibrato e si vuole verificare l'ipotesi che le 10 misure ottenute col primo strumento abbiano lo stesso valore atteso di quelle ottenute col secondo. Inoltre, non disponendo di materiale su cui verificare la durezza sufficientemente grande per realizzare tutte e venti le impronte, si effettuano due a due le misure di durezza su piccoli campioni (`specimen`), considerati internamente omogenei ma non necessariamente tutti uguali:

```{r message=FALSE}
read_table(example_url("hardness2.dat"))
```

Che conclusioni possiamo trarre? rifiutiamo $H_0:~\mu_1=\mu_2$ se sì, con che probabilità d'errore? Cosa cambia con i differenti tipi di test di Student? Cosa possiamo dire sulla loro potenza?

